{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "awutiqx00o7x",
        "outputId": "426d21d3-94a1-4b8a-cc8b-5e174d503d5a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m139.3/139.3 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m14.0/14.0 MB\u001b[0m \u001b[31m103.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m85.7/85.7 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install boto3 tqdm --quiet\n",
        "import requests\n",
        "import pandas as pd\n",
        "import os\n",
        "import json\n",
        "import boto3\n",
        "import time\n",
        "from datetime import datetime, timedelta\n",
        "from botocore.exceptions import NoCredentialsError\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "4Ct8ZWaX0-M0"
      },
      "outputs": [],
      "source": [
        "# --------------------------\n",
        "# 1. Setup directories\n",
        "# --------------------------\n",
        "RAW_DIR = \"staging/raw/api/\"\n",
        "CSV_FILE = \"staging/processed/covid_pakistan.csv\"\n",
        "\n",
        "os.makedirs(RAW_DIR, exist_ok=True)\n",
        "os.makedirs(os.path.dirname(CSV_FILE), exist_ok=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dbxFTqmC1LhR"
      },
      "outputs": [],
      "source": [
        "\n",
        "# --------------------------\n",
        "# 2. AWS S3 Setup\n",
        "# --------------------------\n",
        "AWS_ACCESS_KEY = \"\"\n",
        "AWS_SECRET_KEY = \"\"\n",
        "REGION = \"\"\n",
        "BUCKET_NAME = \"dataingestionandstoring\"\n",
        "\n",
        "s3 = boto3.client(\n",
        "    \"s3\",\n",
        "    aws_access_key_id=AWS_ACCESS_KEY,\n",
        "    aws_secret_access_key=AWS_SECRET_KEY,\n",
        "    region_name=REGION\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "jmVeiesk1Oht"
      },
      "outputs": [],
      "source": [
        "# --------------------------\n",
        "# 3. Function to fetch & save one day's data\n",
        "# --------------------------\n",
        "def fetch_and_save(date_str):\n",
        "    url = f\"https://covid-api.com/api/reports?date={date_str}&iso=PAK&region_name=Pakistan\"\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        response.raise_for_status()\n",
        "        data = response.json()\n",
        "\n",
        "        # Save raw JSON\n",
        "        raw_file = os.path.join(RAW_DIR, f\"pakistan_{date_str}.json\")\n",
        "        with open(raw_file, \"w\") as f:\n",
        "            json.dump(data, f, indent=2)\n",
        "\n",
        "        # Flatten JSON â†’ DataFrame\n",
        "        if \"data\" in data and data[\"data\"]:\n",
        "            df = pd.json_normalize(data[\"data\"])\n",
        "            df[\"report_date\"] = date_str\n",
        "            return df\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Failed for {date_str}: {e}\")\n",
        "    return pd.DataFrame()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "2AyDgvmZ1YVR"
      },
      "outputs": [],
      "source": [
        "# --------------------------\n",
        "# 4. Historical load (2020 â†’ today)\n",
        "# --------------------------\n",
        "def initial_load():\n",
        "    start_date = datetime(2020, 1, 1)\n",
        "    end_date = datetime.utcnow()\n",
        "    all_dfs = []\n",
        "\n",
        "    current_date = start_date\n",
        "    while current_date <= end_date:\n",
        "        date_str = current_date.strftime(\"%Y-%m-%d\")\n",
        "        df = fetch_and_save(date_str)\n",
        "        if not df.empty:\n",
        "            all_dfs.append(df)\n",
        "            print(f\"âœ… Got data for {date_str}\")\n",
        "        current_date += timedelta(days=1)\n",
        "\n",
        "    if all_dfs:\n",
        "        final_df = pd.concat(all_dfs, ignore_index=True)\n",
        "        final_df.to_csv(CSV_FILE, index=False)\n",
        "        print(f\"\\nâœ… Initial CSV saved: {CSV_FILE} with {len(final_df)} rows\")\n",
        "        upload_to_s3(CSV_FILE)\n",
        "    else:\n",
        "        print(\"\\nâš ï¸ No data fetched in initial load!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "FByEGkdl1c5-"
      },
      "outputs": [],
      "source": [
        "# --------------------------\n",
        "# 5. Upload to S3\n",
        "# --------------------------\n",
        "def upload_to_s3(local_file, s3_filename=\"covid_pakistan.csv\"):\n",
        "    \"\"\"\n",
        "    Uploads a file to S3 inside the raw/ folder of your bucket.\n",
        "    Example: s3://dataingestionandstoring/raw/covid_pakistan.csv\n",
        "    \"\"\"\n",
        "    try:\n",
        "        s3_key = f\"raw/{s3_filename}\"   # upload into raw/ folder\n",
        "        s3.upload_file(local_file, BUCKET_NAME, s3_key)\n",
        "        print(f\"â˜ï¸ Uploaded to s3://{BUCKET_NAME}/{s3_key}\")\n",
        "    except FileNotFoundError:\n",
        "        print(\"âŒ Local file not found:\", local_file)\n",
        "    except NoCredentialsError:\n",
        "        print(\"âŒ AWS credentials not available\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "S14QCPMB6FrC"
      },
      "outputs": [],
      "source": [
        "\n",
        "# --------------------------\n",
        "# 6. Incremental updates (every 1 min)\n",
        "# --------------------------\n",
        "def incremental_updates():\n",
        "    while True:\n",
        "        today = datetime.utcnow().strftime(\"%Y-%m-%d\")\n",
        "        print(f\"\\nğŸ”„ Checking API for {today} at {datetime.utcnow()}\")\n",
        "\n",
        "        df_new = fetch_and_save(today)\n",
        "        if not df_new.empty:\n",
        "            if os.path.exists(CSV_FILE):\n",
        "                df_old = pd.read_csv(CSV_FILE)\n",
        "                combined = pd.concat([df_old, df_new], ignore_index=True)\n",
        "                combined = combined.drop_duplicates().reset_index(drop=True)\n",
        "            else:\n",
        "                combined = df_new\n",
        "\n",
        "            combined.to_csv(CSV_FILE, index=False)\n",
        "            print(f\"âœ… Updated CSV with {len(combined)} rows\")\n",
        "\n",
        "            upload_to_s3(CSV_FILE)\n",
        "        else:\n",
        "            print(\"â„¹ï¸ No new data available\")\n",
        "\n",
        "        time.sleep(60)  # wait 1 min\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J1Ii0Vf26Lkn",
        "outputId": "06f40ff9-086c-4ec0-f90d-ec5b2b43ae7f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "â˜ï¸ Uploaded to s3://dataingestionandstoring/raw/covid_pakistan.csv\n"
          ]
        }
      ],
      "source": [
        "upload_to_s3(CSV_FILE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cgTWPQpIBskI",
        "outputId": "e91f4fa4-cd83-4c4f-a6ac-db30f3bb34f6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-3253565031.py:6: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  today = datetime.utcnow().strftime(\"%Y-%m-%d\")\n",
            "/tmp/ipython-input-3253565031.py:7: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  print(f\"\\nğŸ”„ Checking API for {today} at {datetime.utcnow()}\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ğŸ”„ Checking API for 2025-09-20 at 2025-09-20 21:28:04.893686\n",
            "â„¹ï¸ No new data available\n"
          ]
        }
      ],
      "source": [
        "incremental_updates()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CfGvvc1nBusK"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
